{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCQnFPoHrj0A"
   },
   "source": [
    "# DAA M05 Classification and neural networks\n",
    "## Exercise 5.18 - Spam detection with a neural network\n",
    "\n",
    "### Purpose:\n",
    "This notebook fits a neural network to the spam dataset that is described in Section 5.1.2 of Module 5. This code is used in Exercise 5.18.\n",
    "\n",
    "### References:\n",
    "The spam dataset is sourced from the University of California, Irvine Machine Learning Repository:   Hopkins, M., Reeber, E., Forman, G., and Suermondt, J. (1999). Spambase Data Set [Dataset]. https://archive.ics.uci.edu/ml/datasets/Spambase.\n",
    "\n",
    "This dataset contains the following:\n",
    "- 4,601 observations, each representing an email originally collected from a Hewlett-Packard email server, of which 1,813 (39%) were identified as spam;\n",
    "- 57 continuous features:\n",
    "  - 48 features of type ‘word_freq_WORD’ that represent the percentage (0 to 100) of words in the email that match ‘WORD’;\n",
    "  - 6 features of type ‘char_freq_CHAR’ that represent the percentage (0 to 100) of characters in the email that match ‘CHAR’;\n",
    "  - 1 feature, ‘capital_run_length_average’, that is the average length of uninterrupted sequences of capital letters in the email;\n",
    "  - 1 feature, ‘capital_run_length_longest’, that is the length of the longest uninterrupted sequence of capital letters in the email; and\n",
    "  - 1 feature, ‘capital_run_length_total’, that is the total number of capital letters in the email; and\n",
    "- a binary response variable that takes on a value 0 if the email is not spam and 1 if the email is spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApdQIoJ9iO6t"
   },
   "source": [
    "## Packages\n",
    "This section imports the packages that will be required for this exercise/case study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "PtZcfo9S0Iz3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Used to build the neural network and evaluate it.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2i3kNl1iiZxx"
   },
   "source": [
    "## Data\n",
    "This section:\n",
    "- imports the data that will be used in the modelling; and\n",
    "- explores the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdK7T28iicnA"
   },
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PtzjVpkd0I0j",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a list of headings for the data.\n",
    "namearray = [\n",
    "'word_freq_make',\n",
    "'word_freq_address',\n",
    "'word_freq_all',\n",
    "'word_freq_3d',\n",
    "'word_freq_our',\n",
    "'word_freq_over',\n",
    "'word_freq_remove',\n",
    "'word_freq_internet',\n",
    "'word_freq_order',\n",
    "'word_freq_mail',\n",
    "'word_freq_receive',\n",
    "'word_freq_will',\n",
    "'word_freq_people',\n",
    "'word_freq_report',\n",
    "'word_freq_addresses',\n",
    "'word_freq_free',\n",
    "'word_freq_business',\n",
    "'word_freq_email',\n",
    "'word_freq_you',\n",
    "'word_freq_credit',\n",
    "'word_freq_your',\n",
    "'word_freq_font',\n",
    "'word_freq_000',\n",
    "'word_freq_money',\n",
    "'word_freq_hp',\n",
    "'word_freq_hpl',\n",
    "'word_freq_george',\n",
    "'word_freq_650',\n",
    "'word_freq_lab',\n",
    "'word_freq_labs',\n",
    "'word_freq_telnet',\n",
    "'word_freq_857',\n",
    "'word_freq_data',\n",
    "'word_freq_415',\n",
    "'word_freq_85',\n",
    "'word_freq_technology',\n",
    "'word_freq_1999',\n",
    "'word_freq_parts',\n",
    "'word_freq_pm',\n",
    "'word_freq_direct',\n",
    "'word_freq_cs',\n",
    "'word_freq_meeting',\n",
    "'word_freq_original',\n",
    "'word_freq_project',\n",
    "'word_freq_re',\n",
    "'word_freq_edu',\n",
    "'word_freq_table',\n",
    "'word_freq_conference',\n",
    "'char_freq_;',\n",
    "'char_freq_(',\n",
    "'char_freq_[',\n",
    "'char_freq_!',\n",
    "'char_freq_$',\n",
    "'char_freq_#',\n",
    "'capital_run_length_average',\n",
    "'capital_run_length_longest',\n",
    "'capital_run_length_total',\n",
    "'Spam_fl' ]\n",
    "\n",
    "# Read in the data from the Stanford website.\n",
    "# spam = pd.read_csv(\"http://www.web.stanford.edu/~hastie/ElemStatLearn/datasets/spam.data\", delim_whitespace=True, \n",
    "#                    header=None,\n",
    "#                    names=namearray\n",
    "#                  )\n",
    "\n",
    "\n",
    "# Read in the data from the Stanford website.\n",
    "spam = pd.read_csv(\"~/personal/daa_2021s2/Exercises/05 Classification/Datasets/spam.data\", delim_whitespace=True, \n",
    "                   header=None,\n",
    "                   names=namearray\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09rPRrT1ijJH"
   },
   "source": [
    "### Explore data (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LfdpSgVAioVE",
    "outputId": "6d0cf748-32da-4d60-a847-bb34819b03d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   word_freq_make              4601 non-null   float64\n",
      " 1   word_freq_address           4601 non-null   float64\n",
      " 2   word_freq_all               4601 non-null   float64\n",
      " 3   word_freq_3d                4601 non-null   float64\n",
      " 4   word_freq_our               4601 non-null   float64\n",
      " 5   word_freq_over              4601 non-null   float64\n",
      " 6   word_freq_remove            4601 non-null   float64\n",
      " 7   word_freq_internet          4601 non-null   float64\n",
      " 8   word_freq_order             4601 non-null   float64\n",
      " 9   word_freq_mail              4601 non-null   float64\n",
      " 10  word_freq_receive           4601 non-null   float64\n",
      " 11  word_freq_will              4601 non-null   float64\n",
      " 12  word_freq_people            4601 non-null   float64\n",
      " 13  word_freq_report            4601 non-null   float64\n",
      " 14  word_freq_addresses         4601 non-null   float64\n",
      " 15  word_freq_free              4601 non-null   float64\n",
      " 16  word_freq_business          4601 non-null   float64\n",
      " 17  word_freq_email             4601 non-null   float64\n",
      " 18  word_freq_you               4601 non-null   float64\n",
      " 19  word_freq_credit            4601 non-null   float64\n",
      " 20  word_freq_your              4601 non-null   float64\n",
      " 21  word_freq_font              4601 non-null   float64\n",
      " 22  word_freq_000               4601 non-null   float64\n",
      " 23  word_freq_money             4601 non-null   float64\n",
      " 24  word_freq_hp                4601 non-null   float64\n",
      " 25  word_freq_hpl               4601 non-null   float64\n",
      " 26  word_freq_george            4601 non-null   float64\n",
      " 27  word_freq_650               4601 non-null   float64\n",
      " 28  word_freq_lab               4601 non-null   float64\n",
      " 29  word_freq_labs              4601 non-null   float64\n",
      " 30  word_freq_telnet            4601 non-null   float64\n",
      " 31  word_freq_857               4601 non-null   float64\n",
      " 32  word_freq_data              4601 non-null   float64\n",
      " 33  word_freq_415               4601 non-null   float64\n",
      " 34  word_freq_85                4601 non-null   float64\n",
      " 35  word_freq_technology        4601 non-null   float64\n",
      " 36  word_freq_1999              4601 non-null   float64\n",
      " 37  word_freq_parts             4601 non-null   float64\n",
      " 38  word_freq_pm                4601 non-null   float64\n",
      " 39  word_freq_direct            4601 non-null   float64\n",
      " 40  word_freq_cs                4601 non-null   float64\n",
      " 41  word_freq_meeting           4601 non-null   float64\n",
      " 42  word_freq_original          4601 non-null   float64\n",
      " 43  word_freq_project           4601 non-null   float64\n",
      " 44  word_freq_re                4601 non-null   float64\n",
      " 45  word_freq_edu               4601 non-null   float64\n",
      " 46  word_freq_table             4601 non-null   float64\n",
      " 47  word_freq_conference        4601 non-null   float64\n",
      " 48  char_freq_;                 4601 non-null   float64\n",
      " 49  char_freq_(                 4601 non-null   float64\n",
      " 50  char_freq_[                 4601 non-null   float64\n",
      " 51  char_freq_!                 4601 non-null   float64\n",
      " 52  char_freq_$                 4601 non-null   float64\n",
      " 53  char_freq_#                 4601 non-null   float64\n",
      " 54  capital_run_length_average  4601 non-null   float64\n",
      " 55  capital_run_length_longest  4601 non-null   int64  \n",
      " 56  capital_run_length_total    4601 non-null   int64  \n",
      " 57  Spam_fl                     4601 non-null   int64  \n",
      "dtypes: float64(55), int64(3)\n",
      "memory usage: 2.0 MB\n",
      "None\n",
      "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
      "0            0.00               0.64           0.64           0.0   \n",
      "1            0.21               0.28           0.50           0.0   \n",
      "2            0.06               0.00           0.71           0.0   \n",
      "3            0.00               0.00           0.00           0.0   \n",
      "4            0.00               0.00           0.00           0.0   \n",
      "5            0.00               0.00           0.00           0.0   \n",
      "6            0.00               0.00           0.00           0.0   \n",
      "7            0.00               0.00           0.00           0.0   \n",
      "8            0.15               0.00           0.46           0.0   \n",
      "9            0.06               0.12           0.77           0.0   \n",
      "\n",
      "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
      "0           0.32            0.00              0.00                0.00   \n",
      "1           0.14            0.28              0.21                0.07   \n",
      "2           1.23            0.19              0.19                0.12   \n",
      "3           0.63            0.00              0.31                0.63   \n",
      "4           0.63            0.00              0.31                0.63   \n",
      "5           1.85            0.00              0.00                1.85   \n",
      "6           1.92            0.00              0.00                0.00   \n",
      "7           1.88            0.00              0.00                1.88   \n",
      "8           0.61            0.00              0.30                0.00   \n",
      "9           0.19            0.32              0.38                0.00   \n",
      "\n",
      "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
      "0             0.00            0.00  ...         0.00        0.000   \n",
      "1             0.00            0.94  ...         0.00        0.132   \n",
      "2             0.64            0.25  ...         0.01        0.143   \n",
      "3             0.31            0.63  ...         0.00        0.137   \n",
      "4             0.31            0.63  ...         0.00        0.135   \n",
      "5             0.00            0.00  ...         0.00        0.223   \n",
      "6             0.00            0.64  ...         0.00        0.054   \n",
      "7             0.00            0.00  ...         0.00        0.206   \n",
      "8             0.92            0.76  ...         0.00        0.271   \n",
      "9             0.06            0.00  ...         0.04        0.030   \n",
      "\n",
      "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
      "0          0.0        0.778        0.000        0.000   \n",
      "1          0.0        0.372        0.180        0.048   \n",
      "2          0.0        0.276        0.184        0.010   \n",
      "3          0.0        0.137        0.000        0.000   \n",
      "4          0.0        0.135        0.000        0.000   \n",
      "5          0.0        0.000        0.000        0.000   \n",
      "6          0.0        0.164        0.054        0.000   \n",
      "7          0.0        0.000        0.000        0.000   \n",
      "8          0.0        0.181        0.203        0.022   \n",
      "9          0.0        0.244        0.081        0.000   \n",
      "\n",
      "   capital_run_length_average  capital_run_length_longest  \\\n",
      "0                       3.756                          61   \n",
      "1                       5.114                         101   \n",
      "2                       9.821                         485   \n",
      "3                       3.537                          40   \n",
      "4                       3.537                          40   \n",
      "5                       3.000                          15   \n",
      "6                       1.671                           4   \n",
      "7                       2.450                          11   \n",
      "8                       9.744                         445   \n",
      "9                       1.729                          43   \n",
      "\n",
      "   capital_run_length_total  Spam_fl  \n",
      "0                       278        1  \n",
      "1                      1028        1  \n",
      "2                      2259        1  \n",
      "3                       191        1  \n",
      "4                       191        1  \n",
      "5                        54        1  \n",
      "6                       112        1  \n",
      "7                        49        1  \n",
      "8                      1257        1  \n",
      "9                       749        1  \n",
      "\n",
      "[10 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check the dimensions of the data.\n",
    "print(spam.info())\n",
    "\n",
    "# Print the first 10 observations from the data.\n",
    "print(spam.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZZqIwRsi5Xc"
   },
   "source": [
    "## Modelling\n",
    "This section:\n",
    "- fits a model; and\n",
    "- evaluates the fitted model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "for0Y3hai6NC"
   },
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a neural network to classify an email as spam or non-spam.\n",
    "\n",
    "# Change the pandas dataframe to numpy arrays containing the features (X) and response(Y).\n",
    "X = spam.iloc[:,:-1].values # Drops the last column of the dataframe that contains the spam indicator (response).\n",
    "Y = spam.iloc[:,57:58].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise the data so that each feature has mean 0 and standard deviation 1.\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the response variable ('not spam' or 'spam') as 2 outcomes.\n",
    "ohe = OneHotEncoder()\n",
    "Y = ohe.fit_transform(Y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets \n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.25, random_state=42)\n",
    "                                # This separates the data into training (75%) and test (25%) datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.34243371, -0.16507191, -0.55676058, ..., -0.12017005,\n",
       "        -0.22667809, -0.40128076],\n",
       "       [ 1.85195381, -0.16507191, -0.55676058, ..., -0.11181728,\n",
       "        -0.20101998, -0.34520124],\n",
       "       [-0.34243371, -0.16507191,  2.26020736, ...,  0.21633628,\n",
       "         0.3326688 , -0.10933739],\n",
       "       ...,\n",
       "       [-0.34243371, -0.16507191, -0.55676058, ..., -0.09010008,\n",
       "        -0.21641484, -0.38643618],\n",
       "       [-0.34243371,  0.01316257, -0.55676058, ..., -0.11269984,\n",
       "        -0.20101998, -0.18191088],\n",
       "       [-0.01491318, -0.16507191,  0.25658932, ..., -0.10327539,\n",
       "        -0.11891401,  0.09188912]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hQQxkgjE0I2Q",
    "outputId": "c6951cbe-5e5f-4df9-c311-df119ae12cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 1s 6ms/step - loss: 0.7035 - accuracy: 0.5716 - val_loss: 0.6249 - val_accuracy: 0.7446\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.7994 - val_loss: 0.4679 - val_accuracy: 0.8436\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.8617 - val_loss: 0.3473 - val_accuracy: 0.8784\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.3163 - accuracy: 0.8849 - val_loss: 0.2870 - val_accuracy: 0.8923\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2719 - accuracy: 0.9020 - val_loss: 0.2510 - val_accuracy: 0.9070\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2424 - accuracy: 0.9159 - val_loss: 0.2297 - val_accuracy: 0.9149\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2220 - accuracy: 0.9209 - val_loss: 0.2129 - val_accuracy: 0.9253\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.2073 - accuracy: 0.9272 - val_loss: 0.2024 - val_accuracy: 0.9314\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1969 - accuracy: 0.9319 - val_loss: 0.1953 - val_accuracy: 0.9305\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1875 - accuracy: 0.9348 - val_loss: 0.1876 - val_accuracy: 0.9383\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1810 - accuracy: 0.9354 - val_loss: 0.1822 - val_accuracy: 0.9383\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.9354 - val_loss: 0.1795 - val_accuracy: 0.9340\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1704 - accuracy: 0.9365 - val_loss: 0.1757 - val_accuracy: 0.9366\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1672 - accuracy: 0.9365 - val_loss: 0.1722 - val_accuracy: 0.9357\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1632 - accuracy: 0.9380 - val_loss: 0.1712 - val_accuracy: 0.9374\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1598 - accuracy: 0.9391 - val_loss: 0.1672 - val_accuracy: 0.9357\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1565 - accuracy: 0.9397 - val_loss: 0.1646 - val_accuracy: 0.9348\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1534 - accuracy: 0.9400 - val_loss: 0.1631 - val_accuracy: 0.9340\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1502 - accuracy: 0.9417 - val_loss: 0.1602 - val_accuracy: 0.9401\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9409 - val_loss: 0.1593 - val_accuracy: 0.9401\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9435 - val_loss: 0.1583 - val_accuracy: 0.9392\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9438 - val_loss: 0.1555 - val_accuracy: 0.9418\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1398 - accuracy: 0.9446 - val_loss: 0.1549 - val_accuracy: 0.9401\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1376 - accuracy: 0.9464 - val_loss: 0.1533 - val_accuracy: 0.9392\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1357 - accuracy: 0.9458 - val_loss: 0.1531 - val_accuracy: 0.9418\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1330 - accuracy: 0.9487 - val_loss: 0.1506 - val_accuracy: 0.9409\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1314 - accuracy: 0.9490 - val_loss: 0.1479 - val_accuracy: 0.9418\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.9499 - val_loss: 0.1510 - val_accuracy: 0.9418\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1281 - accuracy: 0.9499 - val_loss: 0.1463 - val_accuracy: 0.9427\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1257 - accuracy: 0.9501 - val_loss: 0.1453 - val_accuracy: 0.9461\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1241 - accuracy: 0.9522 - val_loss: 0.1455 - val_accuracy: 0.9444\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1224 - accuracy: 0.9536 - val_loss: 0.1439 - val_accuracy: 0.9461\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.9536 - val_loss: 0.1448 - val_accuracy: 0.9444\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1190 - accuracy: 0.9528 - val_loss: 0.1425 - val_accuracy: 0.9461\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1174 - accuracy: 0.9539 - val_loss: 0.1414 - val_accuracy: 0.9470\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9551 - val_loss: 0.1420 - val_accuracy: 0.9453\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1141 - accuracy: 0.9559 - val_loss: 0.1403 - val_accuracy: 0.9470\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1127 - accuracy: 0.9562 - val_loss: 0.1449 - val_accuracy: 0.9453\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1115 - accuracy: 0.9542 - val_loss: 0.1413 - val_accuracy: 0.9470\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1099 - accuracy: 0.9571 - val_loss: 0.1416 - val_accuracy: 0.9479\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1094 - accuracy: 0.9568 - val_loss: 0.1413 - val_accuracy: 0.9513\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1070 - accuracy: 0.9574 - val_loss: 0.1436 - val_accuracy: 0.9479\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1062 - accuracy: 0.9591 - val_loss: 0.1431 - val_accuracy: 0.9479\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1056 - accuracy: 0.9588 - val_loss: 0.1465 - val_accuracy: 0.9453\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1039 - accuracy: 0.9603 - val_loss: 0.1422 - val_accuracy: 0.9496\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1028 - accuracy: 0.9591 - val_loss: 0.1429 - val_accuracy: 0.9487\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1014 - accuracy: 0.9606 - val_loss: 0.1441 - val_accuracy: 0.9479\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.1004 - accuracy: 0.9626 - val_loss: 0.1438 - val_accuracy: 0.9479\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9638 - val_loss: 0.1454 - val_accuracy: 0.9479\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0974 - accuracy: 0.9641 - val_loss: 0.1467 - val_accuracy: 0.9487\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0964 - accuracy: 0.9638 - val_loss: 0.1522 - val_accuracy: 0.9470\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0952 - accuracy: 0.9649 - val_loss: 0.1473 - val_accuracy: 0.9505\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0944 - accuracy: 0.9646 - val_loss: 0.1485 - val_accuracy: 0.9487\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0934 - accuracy: 0.9672 - val_loss: 0.1506 - val_accuracy: 0.9470\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0919 - accuracy: 0.9675 - val_loss: 0.1542 - val_accuracy: 0.9470\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0913 - accuracy: 0.9670 - val_loss: 0.1539 - val_accuracy: 0.9487\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0899 - accuracy: 0.9675 - val_loss: 0.1516 - val_accuracy: 0.9540\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0895 - accuracy: 0.9678 - val_loss: 0.1526 - val_accuracy: 0.9522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0879 - accuracy: 0.9664 - val_loss: 0.1557 - val_accuracy: 0.9505\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0879 - accuracy: 0.9681 - val_loss: 0.1573 - val_accuracy: 0.9505\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0864 - accuracy: 0.9681 - val_loss: 0.1560 - val_accuracy: 0.9531\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0854 - accuracy: 0.9690 - val_loss: 0.1642 - val_accuracy: 0.9479\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9696 - val_loss: 0.1603 - val_accuracy: 0.9513\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0840 - accuracy: 0.9701 - val_loss: 0.1591 - val_accuracy: 0.9513\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0831 - accuracy: 0.9704 - val_loss: 0.1593 - val_accuracy: 0.9513\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0822 - accuracy: 0.9713 - val_loss: 0.1624 - val_accuracy: 0.9522\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0811 - accuracy: 0.9707 - val_loss: 0.1628 - val_accuracy: 0.9513\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0806 - accuracy: 0.9719 - val_loss: 0.1630 - val_accuracy: 0.9505\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9722 - val_loss: 0.1659 - val_accuracy: 0.9479\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0793 - accuracy: 0.9739 - val_loss: 0.1677 - val_accuracy: 0.9453\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0788 - accuracy: 0.9730 - val_loss: 0.1712 - val_accuracy: 0.9453\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9745 - val_loss: 0.1734 - val_accuracy: 0.9461\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0780 - accuracy: 0.9730 - val_loss: 0.1695 - val_accuracy: 0.9487\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0770 - accuracy: 0.9730 - val_loss: 0.1716 - val_accuracy: 0.9479\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0758 - accuracy: 0.9742 - val_loss: 0.1758 - val_accuracy: 0.9479\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0754 - accuracy: 0.9736 - val_loss: 0.1726 - val_accuracy: 0.9479\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0738 - accuracy: 0.9745 - val_loss: 0.1814 - val_accuracy: 0.9453\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9730 - val_loss: 0.1728 - val_accuracy: 0.9496\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9742 - val_loss: 0.1760 - val_accuracy: 0.9487\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0734 - accuracy: 0.9745 - val_loss: 0.1784 - val_accuracy: 0.9470\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0728 - accuracy: 0.9757 - val_loss: 0.1759 - val_accuracy: 0.9496\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9745 - val_loss: 0.1779 - val_accuracy: 0.9496\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9736 - val_loss: 0.1806 - val_accuracy: 0.9470\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9759 - val_loss: 0.1832 - val_accuracy: 0.9470\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.9751 - val_loss: 0.1791 - val_accuracy: 0.9505\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9759 - val_loss: 0.1810 - val_accuracy: 0.9461\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9754 - val_loss: 0.1848 - val_accuracy: 0.9470\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.9774 - val_loss: 0.1839 - val_accuracy: 0.9461\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9777 - val_loss: 0.1857 - val_accuracy: 0.9479\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9748 - val_loss: 0.1866 - val_accuracy: 0.9470\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9791 - val_loss: 0.1843 - val_accuracy: 0.9496\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9786 - val_loss: 0.1868 - val_accuracy: 0.9470\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9777 - val_loss: 0.1879 - val_accuracy: 0.9487\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9800 - val_loss: 0.1925 - val_accuracy: 0.9479\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9786 - val_loss: 0.1902 - val_accuracy: 0.9487\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9774 - val_loss: 0.1910 - val_accuracy: 0.9487\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9797 - val_loss: 0.1942 - val_accuracy: 0.9479\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9783 - val_loss: 0.1962 - val_accuracy: 0.9487\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9788 - val_loss: 0.1993 - val_accuracy: 0.9496\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9788 - val_loss: 0.1963 - val_accuracy: 0.9487\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a neural network with two hidden layers, containing 28 hidden neurons\n",
    "# (16 neurons in the first hidden layer and 12 neurons in the second hidden layer).\n",
    "model = Sequential()\n",
    "# Create a hidden layer with 16 neurons, an input dimension of 57,\n",
    "# representing the features of the dataset and a ReLU activation function.\n",
    "model.add(Dense(16, input_dim=57, activation=\"relu\"))\n",
    "# Create a second hidden layer with 12 neurons and a ReLU activation function.\n",
    "model.add(Dense(12, activation=\"relu\"))\n",
    "# Create the output layer with 2 neurons representing 'spam' and 'not spam'.\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "# Compile the model using the binary cross entropy loss function (logistic loss),\n",
    "# the Adam optimiser (stochastic gradient descent), and capture\n",
    "# the accuracy of model predictions.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])                                         \n",
    "\n",
    "# Fit the model.\n",
    "history = model.fit(X_train, Y_train,validation_data = (X_test,Y_test), epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IN1fFIdqk3AG"
   },
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "56b1RN57k4iO",
    "outputId": "067743a1-a847-4471-fcf9-8e7b3a4b5c8d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy of the fitted model on the training and test data.\n",
    "plt.plot(history.history['accuracy'], color='dodgerblue')\n",
    "plt.plot(history.history['val_accuracy'],color='orange')\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEELzdjtl1VT"
   },
   "source": [
    "The plot of the model's accuracy against the number of epochs suggests that accuracy on the test data does not improve much beyond approximately 10 epochs (cycles through the full dataset)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DAA_M05_Ex18 v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
